{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "path_to_file = pathlib.Path('./dataset/deu-eng/deu.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "    context = np.array([context for target, context,attr in pairs])\n",
    "    target = np.array([target for target, context,attr in pairs])\n",
    "\n",
    "    return target, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohne Zweifel findet sich auf dieser Welt zu jedem Mann genau die richtige Ehefrau und umgekehrt; wenn man jedoch in Betracht zieht, dass ein Mensch nur Gelegenheit hat, mit ein paar hundert anderen bekannt zu sein, von denen ihm nur ein Dutzend oder weniger nahesteht, darunter höchstens ein oder zwei Freunde, dann erahnt man eingedenk der Millionen Einwohner dieser Welt leicht, dass seit Erschaffung ebenderselben wohl noch nie der richtige Mann der richtigen Frau begegnet ist.\n"
     ]
    }
   ],
   "source": [
    "target_raw, context_raw = load_data(path_to_file)\n",
    "print(context_raw[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mil/yoshikawa/.pyenv/versions/anaconda3-2023.03/envs/machine_translation/lib/python3.10/site-packages/torchtext/transforms.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/mil/yoshikawa/.pyenv/versions/anaconda3-2023.03/envs/machine_translation/lib/python3.10/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/mil/yoshikawa/.pyenv/versions/anaconda3-2023.03/envs/machine_translation/lib/python3.10/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/mil/yoshikawa/.pyenv/versions/anaconda3-2023.03/envs/machine_translation/lib/python3.10/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/mil/yoshikawa/.pyenv/versions/anaconda3-2023.03/envs/machine_translation/lib/python3.10/site-packages/torchtext/functional.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import torchdata.datapipes as dp\n",
    "import torchtext.transforms as T\n",
    "import spacy\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = spacy.load('en_core_web_sm')\n",
    "de = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = './dataset/deu-eng/deu.txt'\n",
    "\n",
    "data_pipe = dp.iter.IterableWrapper([FILE_PATH])\n",
    "data_pipe = dp.iter.FileOpener(data_pipe,mode='rb')\n",
    "data_pipe = data_pipe.parse_csv(skip_lines=0,delimiter='\\t',as_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Go.', 'Geh.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)')\n"
     ]
    }
   ],
   "source": [
    "for sample in data_pipe:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeAttribution(row):\n",
    "    return row[:2]\n",
    "\n",
    "data_pipe = data_pipe.map(removeAttribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Go.', 'Geh.')\n"
     ]
    }
   ],
   "source": [
    "for sample in data_pipe:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engTokenize(text):\n",
    "    \"\"\"Tokenize an English text and return a list of tokens\"\"\"\n",
    "    return [token.text for token in eng.tokenizer(text)]\n",
    "\n",
    "def deTokenize(text):\n",
    "    \"\"\"Tokenizer a German text and return a list of tokens\"\"\"\n",
    "    return [token.text for token in de.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Have', 'a', 'good', 'day', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "print(engTokenize(\"Have a good day !!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Haben', 'Sie', 'einen', 'guten', 'Tag', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "print(deTokenize(\"Haben Sie einen guten Tag!!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(data_iter, place):\n",
    "    for english, german in data_iter:\n",
    "        if place == 0:\n",
    "            yield engTokenize(english)\n",
    "        else:\n",
    "            yield deTokenize(german)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocab = build_vocab_from_iterator(\n",
    "    getTokens(data_pipe,0),\n",
    "    min_freq=2,\n",
    "    specials=['<pad>','<sos>','<eos>','<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "source_vocab.set_default_index(source_vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab = build_vocab_from_iterator(\n",
    "    getTokens(data_pipe,1),\n",
    "    min_freq=2,\n",
    "    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "target_vocab.set_default_index(target_vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<sos>', '<eos>', '<unk>', '.', 'I', 'Tom', 'to', 'you']\n"
     ]
    }
   ],
   "source": [
    "print(source_vocab.get_itos()[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13610, 24266)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_vocab.get_itos()),len(target_vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransform(vocab):\n",
    "    text_transform = T.Sequential(\n",
    "        T.VocabTransform(vocab=vocab),\n",
    "        T.AddToken(1, begin=True),\n",
    "        T.AddToken(2,begin=False)\n",
    "    )\n",
    "    return text_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sentence=I changed.\n",
      "Transformed sentence[1, 5, 510, 4, 2]\n",
      "<sos>Ichanged.<eos>"
     ]
    }
   ],
   "source": [
    "temp_list = list(data_pipe)\n",
    "some_sentence = temp_list[798][0]\n",
    "print('Some sentence=',end=\"\")\n",
    "print(some_sentence)\n",
    "transformed_sentence = getTransform(source_vocab)(engTokenize(some_sentence))\n",
    "print(\"Transformed sentence\",end=\"\")\n",
    "print(transformed_sentence)\n",
    "index_to_string = source_vocab.get_itos()\n",
    "for index in transformed_sentence:\n",
    "    print(index_to_string[index],end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 617, 4, 2], [1, 743, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "def applyTransform(sequence_pair):\n",
    "    return (\n",
    "        getTransform(source_vocab)(engTokenize(sequence_pair[0])),\n",
    "        getTransform(target_vocab)(deTokenize(sequence_pair[1]))\n",
    "    )\n",
    "data_pipe = data_pipe.map(applyTransform)\n",
    "temp_list = list(data_pipe)\n",
    "print(temp_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortBucket(bucket):\n",
    "    return sorted(bucket,key=lambda x:(len(x[0]),len(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe = data_pipe.bucketbatch(\n",
    "    batch_size = 4, batch_num=5,bucket_num=1,\n",
    "    use_in_batch_shuffle=False,sort_key=sortBucket\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([1, 5, 837, 195, 2], [1, 7, 22, 913, 24, 2]), ([1, 5, 837, 4, 2], [1, 7, 22, 913, 4, 2]), ([1, 2119, 107, 195, 2], [1, 4732, 5, 1364, 24, 2]), ([1, 5, 1295, 4, 2], [1, 7, 22, 31, 1473, 4, 2])]\n"
     ]
    }
   ],
   "source": [
    "print(list(data_pipe)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateSourceTarget(data):\n",
    "    sources = []\n",
    "    target = []\n",
    "    for src,tgt in data:\n",
    "        sources.append(src)\n",
    "        target.append(tgt)\n",
    "    return sources, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_pipe \u001b[38;5;241m=\u001b[39m \u001b[43mseparateSourceTarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_pipe\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m, in \u001b[0;36mseparateSourceTarget\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m sources \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m target \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m src,tgt \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m      5\u001b[0m     sources\u001b[38;5;241m.\u001b[39mappend(src)\n\u001b[1;32m      6\u001b[0m     target\u001b[38;5;241m.\u001b[39mappend(tgt)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "data_pipe = separateSourceTarget(data_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3030, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "print(data_pipe[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos>KissTom.<eos>"
     ]
    }
   ],
   "source": [
    "sentence = data_pipe[0][543]\n",
    "source_index_to_string = source_vocab.get_itos()\n",
    "for index in sentence:\n",
    "    print(source_index_to_string[index],end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos>KüsseTom!<eos>"
     ]
    }
   ],
   "source": [
    "sentence = data_pipe[1][543]\n",
    "target_index_to_string = target_vocab.get_itos()\n",
    "for index in sentence:\n",
    "    print(target_index_to_string[index],end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyPadding(sentences):\n",
    "    return T.ToTensor(0)(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad = applyPadding(data_pipe[0])\n",
    "tgt_pad = applyPadding(data_pipe[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(len(src_pad)):\n",
    "    dataset.append((src_pad[i],tgt_pad[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1, 617,   4,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0]),\n",
       " tensor([  1, 743,   4,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4343"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "import torch\n",
    "\n",
    "src_vocab_size = 13610\n",
    "tgt_vocab_size = 24266\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "\n",
    "# Generate random sample data\n",
    "src_data = torch.randint(1, src_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)\n",
    "tgt_data = torch.randint(1, tgt_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data = torch.randint(1, src_vocab_size, (64, 126)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print('type',type(src_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1762, 1018, 3091,  ..., 1495, 1284, 1716],\n",
      "        [ 485, 3838, 3967,  ..., 2934, 1690,  555],\n",
      "        [2070, 3051, 3599,  ..., 4877, 3526, 4000],\n",
      "        ...,\n",
      "        [3233,  998, 3065,  ..., 2590,  993, 1436],\n",
      "        [4559, 3718,  426,  ..., 4844, 4622, 4751],\n",
      "        [1097, 1925, 4470,  ..., 2806, 1961, 2375]])\n"
     ]
    }
   ],
   "source": [
    "print(src_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,   6,  13,  ...,   0,   0,   0],\n",
      "        [  1,   5,  31,  ...,   0,   0,   0],\n",
      "        [  1, 240,  75,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  1,  95,  11,  ...,   0,   0,   0],\n",
      "        [  1,   6, 698,  ...,   0,   0,   0],\n",
      "        [  1,   5,  79,  ...,   0,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "for batch,(source,target) in enumerate(data_loader):\n",
    "    print(source)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 0\n",
      "source torch.Size([64, 113])\n",
      "type <class 'torch.Tensor'>\n",
      "target torch.Size([64, 90])\n",
      "loss tensor(10.2315, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "import torch.nn as nn\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for batch,(source,target) in enumerate(data_loader):\n",
    "        print('source',batch)\n",
    "        print('source',source.shape)\n",
    "        print('type',type(source))\n",
    "        print('target',target.shape)\n",
    "        output = transformer(source,target[:,:-1])\n",
    "        # print('output',output.contiguous().view(-1,tgt_vocab_size).shape)\n",
    "        # print('target',target[:,1:].contiguous().view(-1).shape)\n",
    "        ##output = transformer(src_data,tgt_data[:,:-1])\n",
    "        loss = loss_fn(output.contiguous().view(-1,tgt_vocab_size),target[:,1:].contiguous().view(-1))\n",
    "        ##loss = loss_fn(output.contiguous().view(-1,tgt_vocab_size),tgt_data[:,1:].contiguous().view(-1))\n",
    "        print('loss',loss)\n",
    "        break\n",
    "    break\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_translation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
